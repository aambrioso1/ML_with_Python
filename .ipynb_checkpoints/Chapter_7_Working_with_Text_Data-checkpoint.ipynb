{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a870fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -nc http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -P data\n",
    "! tar -xzf data/aclImdb_v1.tar.gz -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a155cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree -dL 2 data/aclImdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed6a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r data/aclImdb/train/unsup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd8a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# pip install mglearn # Note that for my new MacBook, I need to install this package.\n",
    "import mglearn # https://github.com/amueller/introduction_to_ml_with_python/tree/master/mglearn\n",
    "# from preamble import *\n",
    "\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(\"data/aclImdb/train/\")\n",
    "# load_files returns a bunch, containing training texts and training labels\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "print(\"type of text_train: {}\".format(type(text_train)))\n",
    "print(\"length of text_train: {}\".format(len(text_train)))\n",
    "\n",
    "print(20*\"*\")\n",
    "for i in range(7):\n",
    "    print(20*\"*\")\n",
    "    print(f\"text_train[{i}]:\\n{text_train[i]}\")\n",
    "    print(20*\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train] # Replaces all the HTML line break tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860fd820",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(20*\"*\")\n",
    "for i in range(7):\n",
    "    print(20*\"*\")\n",
    "    print(\"text_train[i]:\\n{}\".format(text_train[i]))\n",
    "    print(20*\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(text_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c031e3e2",
   "metadata": {},
   "source": [
    "Should read documentation on strings and Unicode:  [Unicode](https://docs.python.org/3/howto/unicode.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd25db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60222c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Samples per class (training): {}\".format(np.bincount(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files(\"data/aclImdb/test/\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "print(\"Number of documents in test data: {}\".format(len(text_test)))\n",
    "print(\"Samples per class (test): {}\".format(np.bincount(y_test)))\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2504b691",
   "metadata": {},
   "source": [
    "### 7.3. Representing Text Data as a Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84cafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bards_words =[\"The fool doth think he is wise,\",\n",
    "              \"but the wise man knows himself to be a fool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(bards_words) # Labels every word in the vocabulary with a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e3a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"Vocabulary content:\\n {}\".format(vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each sentence is turned into a bag of words (array) with the count of each word in the array listed in order based\n",
    "# on the labels assigned by vect.vocabulary_.\n",
    "bag_of_words = vect.transform(bards_words) \n",
    "print(\"bag_of_words: {}\".format(repr(bag_of_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f04ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dense representation of bag_of_words:\\n{}\".format(\n",
    "    bag_of_words.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf7de85",
   "metadata": {},
   "source": [
    "### 7.3.2 Bag-of-word for movie reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4cbc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb155065",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names_out() # Note that this command is the new version\n",
    "# feature_names = vect.get_feature_names() # This version of the command has been deprecated since book was published.\n",
    "print(\"Number of features: {}\".format(len(feature_names)))\n",
    "print(\"First 20 features:\\n{}\".format(feature_names[:20]))\n",
    "print(\"Features 20010 to 20030:\\n{}\".format(feature_names[100:900]))\n",
    "print(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "scores = cross_val_score(LogisticRegression(), X_train, y_train, cv=5)\n",
    "print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b9d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbeb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print(\"Test score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train with min_df: {}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "print(\"First 50 features:\\n{}\".format(feature_names[:50]))\n",
    "print(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030]))\n",
    "print(\"Every 700th feature:\\n{}\".format(feature_names[::700]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02842b5c",
   "metadata": {},
   "source": [
    "### 7.4 Stopwords\n",
    "\n",
    "### [Start here](https://github.com/amueller/introduction_to_ml_with_python/blob/master/07-working-with-text-data.ipynb) with input 22 (pp. 341 in the book).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75baf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "print(\"Number of stop words: {}\".format(len(ENGLISH_STOP_WORDS)))\n",
    "print(\"Every 10th stopword:\\n{}\".format(list(ENGLISH_STOP_WORDS)[::10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1691b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
